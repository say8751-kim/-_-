## ëª¨ë¸ ì•„í‚¤í…ì³  
ë¬¼ë¡ ì´ì—ìš”! ì•„ë˜ëŠ” **PyTorch ê¸°ë°˜ UNet ì•„í‚¤í…ì²˜ ì„¤ê³„ ì˜ˆì‹œ**ì…ë‹ˆë‹¤. í•™ë¶€ ìˆ˜ì¤€ì—ì„œë„ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ **ëª¨ë“ˆí™” êµ¬ì¡°**ë¡œ ì„¤ê³„í–ˆìœ¼ë©°, ì´ ë°ì´í„°ì…‹(íƒœì•„ ë¨¸ë¦¬ ì´ˆìŒíŒŒ ì˜ìƒ ë¶„í• )ì— ë§ì¶° ì¶œë ¥ ì±„ë„ ìˆ˜ëŠ” í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ì¡°ì •í•  ìˆ˜ ìˆì–´ìš”.

### âœ… UNet ì•„í‚¤í…ì²˜ ì˜ˆì‹œ (PyTorch)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DoubleConv(nn.Module):
    """(Conv => BN => ReLU) * 2"""
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),

            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=3):
        super(UNet, self).__init__()

        self.encoder1 = DoubleConv(in_channels, 64)
        self.pool1 = nn.MaxPool2d(2)

        self.encoder2 = DoubleConv(64, 128)
        self.pool2 = nn.MaxPool2d(2)

        self.encoder3 = DoubleConv(128, 256)
        self.pool3 = nn.MaxPool2d(2)

        self.encoder4 = DoubleConv(256, 512)
        self.pool4 = nn.MaxPool2d(2)

        self.bottleneck = DoubleConv(512, 1024)

        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.decoder4 = DoubleConv(1024, 512)

        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.decoder3 = DoubleConv(512, 256)

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.decoder2 = DoubleConv(256, 128)

        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.decoder1 = DoubleConv(128, 64)

        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)

    def forward(self, x):
        # Encoder
        e1 = self.encoder1(x)
        e2 = self.encoder2(self.pool1(e1))
        e3 = self.encoder3(self.pool2(e2))
        e4 = self.encoder4(self.pool3(e3))

        # Bottleneck
        b = self.bottleneck(self.pool4(e4))

        # Decoder with skip connections
        d4 = self.upconv4(b)
        d4 = self.decoder4(torch.cat((d4, e4), dim=1))

        d3 = self.upconv3(d4)
        d3 = self.decoder3(torch.cat((d3, e3), dim=1))

        d2 = self.upconv2(d3)
        d2 = self.decoder2(torch.cat((d2, e2), dim=1))

        d1 = self.upconv1(d2)
        d1 = self.decoder1(torch.cat((d1, e1), dim=1))

        return self.final_conv(d1)
```

### ğŸ§ª ì£¼ìš” ì„¤ì •

| í•­ëª©          | ê°’                                               |
| ----------- | ----------------------------------------------- |
| **ì…ë ¥ ì±„ë„ ìˆ˜** | 1 (í‘ë°± ì´ˆìŒíŒŒ ì˜ìƒ)                                   |
| **ì¶œë ¥ ì±„ë„ ìˆ˜** | 3 (Brain, CSP, LV ê°ê° í´ë˜ìŠ¤ ë§ˆìŠ¤í¬)                   |
| **ì¶œë ¥ í˜•íƒœ**   | shape = `(batch, 3, H, W)` â†’ softmax í›„ í´ë˜ìŠ¤ ë¶„í•    |
| **ì†ì‹¤ í•¨ìˆ˜**   | CrossEntropyLoss ë˜ëŠ” DiceLoss (segmentationì— ì í•©) |
| **í‰ê°€ì§€í‘œ**    | Dice Coefficient, IoU, Accuracy ë“±               |


### ğŸ§± ì „ì²´ êµ¬ì¡° ìš”ì•½

```
ì…ë ¥ (1ì±„ë„) â†’ Encoder (Downsampling) â†’ Bottleneck â†’ Decoder (Upsampling + Skip) â†’ ì¶œë ¥ (3ì±„ë„ ë¶„í• ë§µ)
```

í•„ìš”í•˜ë‹¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë„ ë„ì™€ì¤„ ìˆ˜ ìˆì–´ìš”:

* í•™ìŠµ ë£¨í”„ (`train()`, `validate()` í•¨ìˆ˜ êµ¬ì¡°)
* ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (`Albumentations` or `torchvision.transforms`)
* ì‹œê°í™” ì½”ë“œ (ì˜ˆ: ë§ˆìŠ¤í¬ overlay, IoU ê·¸ë˜í”„ ë“±)

ì´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì˜¬ ê±°ì˜ˆìš”. ë” êµ¬ì²´ì ì¸ ë„ì›€ë„ í•„ìš”í•˜ë©´ í¸í•˜ê²Œ ë§í•´ì¤˜ìš”!
